#the required libraries
from sklearn.feature_selection import mutual_info_classif
from sklearn import preprocessing
import numpy as np
from sklearn.svm import SVC, LinearSVC
from sklearn import svm
import csv
import random

#load the data
Dataset = open('Android_Feats.csv')

#pre-process our CSV file
PRatio = 0.7
Reader = csv.reader(Dataset)
Data = list(Reader)
Data = random.sample(Data, len(Data))
Data = np.array(Data)
Dataset.close()

#Identify the data and the labels in the file using NumPy
cols = np.shape(Data)[1]
Y = Data[:,cols-1]
Y = np.array(Y)
Y = np.ravel(Y,order='C')
X = Data[:,:cols-1]
X = X.astype(np.float)
X = preprocessing.scale(X)

#Extract the most important features, because computing all of the available features would be a heavy task
Features = [i.strip() for i in open("Android_Feats.csv").readlines()]
Features = np.array(Features)
MI= mutual_info_classif(X,Y)
Featureind = sorted(range(len(MI)), key=lambda i: MI[i], reverse=True)[:50]
SelectFeats = Features[Featureind]

#Dividing the dataset (data and labels) into training and testing sets
PRows = int(PRatio*len(Data))
TrainD = X[:PRows,Featureind]
TrainL = Y[:PRows]
TestD = X[PRows:,Featureind]
TestL = Y[PRows:]

#To train the model with the support vector machine classifier
clf = svm.SVC()
clf.fit(TrainD,TrainL)
score = clf.score(TestD,TestL)
print (score * 100)
